<html>
	<head>
		<meta charset = "UTF-8">
		<script language="javascript" type="text/javascript" src="https://cdn.jsdelivr.net/npm/p5@1.3.1/lib/p5.min.js"></script>
		<title>ML Review</title>
		<link rel="preconnect" href="https://fonts.gstatic.com">
		<link href="https://fonts.googleapis.com/css2?family=Lato:wght@300&display=swap" rel="stylesheet">
		<style>
			html {
				background-color: lightgray;
			}
			body {
				font-family: 'Lato', sans-serif;
			}
			h1 {
				text-align: center;
				font-weight: "bold";
			}
			#ul {
				text-decoration: underline;
			}
			h2 {
				text-align: center;
				font-weight: "bold";
				text-decoration: underline;
			}
			li {
				padding: 2px;
				text-align: justify;
			}
			p, h3 {
				text-align: center;
			}
			#lr {
				text-align: center;
			}
			canvas {
				position: absolute; 
				left: 50%; 
				margin-left: -300px; 
				padding-top: 5px; 
			}
			img {
				width: 100%;
			}
		</style>
	</head>
	<body>
		<h1 id = "ul">Arjun's Machine Learning Review Webpage</h1>

		<p><strong>What have I directly observed?</strong> I have observed that there are a lot of libraries that you can use to build ML models that make the process a lot easier. They make it very easy to test out different functionality and try out different things like activation functions, optimizers, number of epochs, and the learning rate. They also make it extremely simple to add and remove new layers and neurons.</p>
		<p><strong>What do I think?</strong> I think that there were a lot of difference in just the last two Colab notebooks we looked at / designed. That makes it a lot more difficult to understand how to build a neural network and how it works, because the code is so different for each with very little explanation on what each of the lines are doing. While it gives an overview of what a chunk of code does, it would be helpful to understand specifically what each line is doing so we don't have to copy the entire example when building our own projects.</p>
		<p><strong>What do I understand?</strong> I understand the WHY of why/how machine learning models work. I understand the math that goes on and how it evaulates inputs, etc. But, I don't fully understand the HOW. How does back propagation work? How can I teach a neural network to learn something and be trained without being handed a library that can do it for me? How can I make my projects unique rather than what the person who designed the library wants users to make?</p>
		<p><strong>What am I trying to learn more about, and / or what would I like to understand better?</strong> I would like to better understand how neural networks learn by adjusting their weights and biases. I think it would be interesting to try and learn how to make an ML bot that can do that without using and pre-made libraries. Also, I have seen in AI youtube videos of visual ML models that show the nodes and connections lighting up as the neurons fire. I would like to learn how to make that be visualized as well.</p>

		<div>
			<h2>Some other important links we have used:</h2>
			<ul>
				<li><a href = "https://medium.com/tebs-lab/introduction-to-deep-learning-a46e92cb0022">Intro to Deep Learning</a></li>
				<li><a href = "https://docs.google.com/document/d/1w65GznE6N5EPLFG2KQr5oNM8ZDbY6N24IcuYYduz4y4/edit?usp=sharing">Index of Projects</a></li>
				<li><a href = "https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a></li>
			</ul>
		</div>

		<div>
			<h2>My projects!</h2>
			<ul>
				<li><a href = "https://teachablemachine.withgoogle.com/models/KYN_TuJY3/">Hunger Games Books Classfier</a></li>
				<li><a href = "https://teachablemachine.withgoogle.com/models/c_3DrfGea/">Stringed Instrument Classifer</a></li>
				<li><a href = "https://teachablemachine.withgoogle.com/models/WuL3w5m7i/">Red/Green/Blue Audio Classifier</a></li>
				<li><a href = "https://teachablemachine.withgoogle.com/models/NrhxHWD5d/">Cello Strings Audio Classifier</a></li>
				<li><a href = "https://teachablemachine.withgoogle.com/models/W-R8WL3Fs/">Arms Up Poses Classifier</a></li>
				<li><a href = "https://teachablemachine.withgoogle.com/models/3AaxTwiO3/">Dance Poses Classifier</a></li>
				<li><a href = "https://arjun-pose-recognizer.glitch.me">Glitch Webpage</a></li>
				<li><a href = "https://arjunsingh403.github.io/Word2Vec/">Word2Vec</a></li>
				<li><a href = "https://arjunsingh403.github.io/linearregression/">Linear Regression Github Pages</a></li>
			</ul>
		</div>

		<h2>Vocabulary</h2>
		<ul>
			<li><strong><u>Model:</u></strong> A machine learning model is a program that is trained using initial sample data to process additional data and make predictions using learned patterns. ML models are not explicitly coded to carry out their tasks; instead, they learn automatically using sample data.</li>
			<li><strong><u>Samples:</u></strong> Samples are the example data that are used as training samples and test samples (which are defined later on) during the ML model’s training. Samples for classification models are manually classified ahead of time by humans, so the program knows what it is learning to classify and can compare test samples to training samples.</li>
			<li><strong><u>Class:</u></strong> With regard to classification ML models, classes are the categories that models aim to sort new data into. For simple models such as those built on Teachable Machine, any potential class the model can sort new data into must be defined during the model’s training stages.</li>
			<li><strong><u>Training:</u></strong> Training refers to the process by which ML models learn and improve their abilities to detect patterns and carry out tasks automatically (without being hard-coded to do so). The process normally involves multiple iterations of using some samples to detect and learn patterns, and others to test the model’s current capabilities.</li>
			<li><strong><u>Epoch:</u></strong> The number of epochs in an ML model’s training refers to the number of times that the model works through the entire sample data set. Models tend to increase their accuracy and decrease their loss (which are defined later on) with each additional epoch, so training with more epochs tends to make a more robust model. However, accuracy and loss will plateau after a certain point. </li>
			<li><strong><u>Batch Size:</u></strong> The batch size in an ML model’s training refers to the number of samples the model will work through before updating its internal parameters. The model loops through each batch, making predictions, and at the end of the batch, the model compares its predictions to test data and calculates the error. From this, an update algorithm improves upon the model.</li>
			<li><strong><u>Learning Rate:</u></strong> An ML model’s learning rate is a metaphorical representation of how quickly the model “learns”. It is one parameter in the model’s algorithm that determines the step size at each iteration while trying to achieve the lowest possible loss.</li>
			<li><strong><u>Training Samples vs Test Samples:</u></strong> During an ML model’s training, the data samples are separated into two categories: training samples and test samples. ML models on Teachable Machine maintain a ratio of about 85% of the samples being training samples, and the rest being test samples. The model first analyzes the training samples to learn how to classify new data, then practices using the never-seen-before test samples to test accuracy and confidence.</li>
			<li><strong><u>Underfit:</u></strong> “Underfitting” describes the effect when an ML model does not fully capture the complexity of the training samples, and ends up with too broad a classification range. In other words, the model develops such a broad understanding of what a certain class can be that it classifies new data poorly because it thinks two different things can be the same thing.</li>
			<li><strong><u>Overfit:</u></strong> “Overfitting” describes the effect when an ML model learns based on the training samples so specifically that it is unable to identify any new sample data, including test samples. The model develops such a specific understanding of what a certain class can be that it classifies new data poorly because it doesn’t think there can be a difference between it and training data.</li>
			<li><strong><u>Accuracy per Class:</u></strong> Accuracy per class is a measure, expressed as a percentage, of how many test samples out of the total number of test samples (for a given class) that the model is able to correctly classify during training. This measure is unaffected by how confident the model is for any classification; it simply looks at whether the classification was correct or not.</li>
			<li><strong><u>Confusion Matrix:</u></strong> A confusion matrix is a summary of the predictions made by an ML model. It shows the ways in which a classification model is confused when it makes predictions, and gives insight into the types of errors being made.</li>
			<li><strong><u>Accuracy per Epoch:</u></strong> Accuracy per epoch is a measure, expressed as a percentage, of how many test samples out of the total number of test samples an ML model is able to correctly classify in a given epoch. When plotted on a graph, the trend gives you a sense of how much the model is learning and improving with each additional epoch. This measure is unaffected by how confident the model is for any classification; it simply looks at whether the classification was correct or not.</li>
			<li><strong><u>Loss per Epoch:</u></strong> Loss per epoch is a measure, expressed as a percentage, of how confident an ML model is in its predictions in a given epoch. This measure is unaffected by whether the model correctly classifies new data; it just looks at how confident it is in its prediction. When plotted on a graph, the trend gives you a sense of if the model is getting more confident (and therefore more accurate) in its predictions with each additional epoch.</li>
		</ul>

		<h2>Activation Functions</h2>
		<ul>
			<li><strong><u>What exactly is an activation function, and generally speaking why is it important for ML with NNs?</u></strong> An activation function in a neural network is a function that defines how the weighted sum of the input is transformed into an output from a node or nodes in a layer of the network (ML Mastery). Activation functions with a limited output range are helpful for keeping outputs within a fixed range. Additionally, nonlinear activation functions contribute to the “nonlinearity” of layers in a neural network.</li>
			<li><strong><u>In the examples of multilayer neural networks we have built and played with so far, there are weights and biases making adjustments to inputs, but we have seen we still need to have the activation function on top of weights and biases; so in your own words, what distinguishes the activation function from weights and biases?</u></strong> One difference between activation functions and weights and biases in a neural network is that the activation function is applied after the weights and biases have been applied to each set of inputs. If the neural network requires an activation function with a limited output range such as sigmoid, not applying an activation function could result in extreme results as the weights and biases yield outputs that are too large. Activation functions are necessary to keep the outputs of each node within the range that the neural network can handle, so the network does not yield extreme and incorrect results. Another important distinction between activation functions and weights and biases is once defined, activation functions cannot be modified by the neural network. During the process of learning, neural networks often adjust their weights (and sometimes biases) to fit the training data, but it will never modify the activation function.</li>
			<li><strong><u>What differences are there between different activations (sigmoid, ReLU, etc.), and why might one activation be better suited to a given project than another? Explain with citations to the readings below.</u></strong> Citations: ML Cheatsheet and ML Mastery. One key difference between activation functions is their output range. Some activation functions, such as linear, ELU, and ReLU, have an unlimited range and will output values directly proportional to the input value (sometimes after a threshold), no matter how extreme. But, other activation functions, such as sigmoid and tanh, have a limited range. This difference can make one type of activation function better suited for a project than another; for example, in some neural networks (like XOR) you want your output to simply be true or false. Activation functions like sigmoid with a limited range are better suited to this project because you can assign an output of 1 to be true and an output of 0 to be false (or some other straightforward format), whereas activation functions with an unlimited range do not always yield such simple and comprehensible outputs. It may also be helpful to use one type of activation function over another given the magnitude of the weights and biases in the neural network (if they are predetermined like in our XOR example). For example, if the weights and biases have a magnitude greater than 1, it may be beneficial to use an activation function with a limited range, so outputs do not grow out of control. However, if the weights and biases have a magnitude that is less than 1 (like the other examples we explored in class), other activation functions can be used just fine. Activation functions with an unlimited range like ReLU may also be better if you want your outputs to easily correspond to your inputs, and have a wide variety of potential outputs. It is important to note that while you must use the same activation function for the entirety of any given layer in a neural network, you can use different activation functions across layers. Thus, the choice of which activation function you use on each layer depends on what you want your outputs to be like.</li>
		</ul>

		<h2>Simple Neural Network (for XOR)</h2>
		<img src="xor.png" alt="XOR Neural Network">
		<img src="math.png">
		<img src="sigmoid.png">
		<img src="eq.png">

		<div>
			<h1><a href = "https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a> Grapher</h1>
			<h3>Click the graph to add data points. The program will automatically plot the <a href = "https://en.wikipedia.org/wiki/Line_fitting">line of best fit.</a></h3>
			<h3>(600x600px Canvas)</h3>
			<p>Slope:</p>
			<p id = "slope">NaN</p>
			<p>Y-Intercept:</p>
			<p id = "yint">NaN</p>

			<script src="script1.js"></script>
		</div>

		<div>
			<h1><a href = "https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a> using <a href = "https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a></h1>
			<p>Click to plot points. The computer will calculuate the regression line using gradient descent.</p>
			<p>Input a learning rate below (0 - 100). Press ESC to reset.</p>
			<div id = "lr">
				<input id = "learningrate" type = "number" value = 50>
			</div>
			<p id = "equation">Regression Equation: y = m * x + b</p>
			<script src="script2.js"></script>
		</div>
	</body>
</html>
